{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Quantitative Research Approaches  \n",
    "Lecture 1\n",
    "\n",
    "# Getting started, descriptive statistics, Jupyter and Pandas\n",
    "\n",
    "Prof Miles Berry  \n",
    "23/1/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectures  \n",
    "\n",
    "23/1 Face to face: getting started, descriptive statistics, Jupyter and Pandas  \n",
    "30/1 Independent study: descriptive statistics and visualising data  \n",
    "6/2 Face to face: constructing surveys with Likert scales; visualisations and comparisons  \n",
    "13/2 Independent study: surveys and student satisfaction  \n",
    "20/2 Face to face: linear models and school performance data  \n",
    "27/2 Independent study: deep diving into a GCSE subejct  \n",
    "5/3 Face to face: randomised control trials  \n",
    "12.3 Face to face: geographical data  \n",
    "19/3 Independent study: international comparisons  \n",
    "26/3 Independent study: preparing for the assignment  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "\n",
    "We agree a suitable dataset for the assignment. I support you in preparing this for analysis. You import the data to a suitable platform and provide descriptive statistics and some exploratory visualisations. You identify three interesting questions based on the dataset and offer further visualisations and analysis to answer these. You document this process through a narrative and by inclusion of source code or equivalent. You reflect critically on your approach and conclusions, by reference to the literature on research methods and similar studies. \n",
    "\n",
    "Due date 1/5/24 at 2:00 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the truth out there?\n",
    "\n",
    "### Constructivism\n",
    "People construe the world differently  \n",
    "Discovering how people interpret the world  \n",
    "Theory as sets of meanings to make sense of the world  \n",
    "Search for meaning, relationships, consequences  \n",
    "Represent, analyse, compare  \n",
    "  \n",
    "### Positivism  \n",
    "The world exists and is knowable  \n",
    "Discovering laws of society  \n",
    "Theory as explanation of behaviour  \n",
    "Experimental validation of theory  \n",
    "Abstraction of reality  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative research\n",
    "\n",
    ">The social and educational world is a messy place, full of contradictions, richness, complexity, connectedness, conjunctions and disjunctions. It is multilayered, and not easily susceptible to the atomization process inherent in much numerical research. It has to be studied in total rather than in fragments if a true understanding is to be reached.\n",
    "\n",
    "Cohen, Manion and Morrison, 2011, p. 219"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Quantitative research is scientific investigation that includes both experiments and other systematic methods that emphasize control and quantified measures of performance. Measurement and statistics are central to quantitative research because they are the connections between empirical observation and mathematical expressions of relations... Quantitative researchers are concerned with the development and testing of hypotheses and the generation of models and theories that explain behaviour.\n",
    "\n",
    "[Hoy, W. K., Adams, C. M. and Adams, C. M. (2016)](https://roehamptonuniversity.on.worldcat.org/oclc/910073188)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence informed education\n",
    "\n",
    ">I think there is a huge prize waiting to be claimed by teachers. By collecting better evidence about what works best, and establishing a culture where this evidence is used as a matter of routine, we can improve outcomes for children, and increase professional independence.\n",
    "\n",
    "[Goldacre, 2013](https://assets.publishing.service.gov.uk/media/5a7a219140f0b66eab999f4f/Building_evidence_into_education.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of data\n",
    "\n",
    "* Qualitative - text, images, video, audio\n",
    "* Quantitative - numbers, or things that can be turned into numbers!\n",
    "  * Categories - nominal, ordinal\n",
    "  * Discrete - countable\n",
    "  * Continuous - measurable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stevens's Scales of Measurement\n",
    "\n",
    "- nominal  \n",
    "- ordinal  \n",
    "- interval  \n",
    "- ratio\n",
    "\n",
    "[Stevens (1946)](https://psychology.okstate.edu/faculty/jgrice/psyc3214/Stevens_FourScales_1946.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stevens's Scales of Measurement](images/stevens0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stevens's Scales of Measurement](images/stevens1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data science (and qualitative methods)\n",
    "\n",
    "![Data cycle](images/workflow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Python\n",
    "\n",
    "Python is a general purpose programming language, which is widely used in data science. It's free and open source, and runs on Windows, Mac and Linux. It's easy to learn, and has a large and active community of users and developers.\n",
    "\n",
    "We're using Jupyter Notebooks, which are a way of combining text, code and output in a single document. You can run these on your own computer, or use a cloud service such as [Google Colab](https://colab.research.google.com/), as we're using here.\n",
    "\n",
    "I start by loading some standard libraries and setting some options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint # pseudorandom whole numbers\n",
    "from math import sqrt      # squareroots\n",
    "\n",
    "import matplotlib.pyplot as plt # basic graphics library\n",
    "\n",
    "plt.style.use('ggplot')    # ggplot style graphics\n",
    "plt.rcParams['figure.figsize'] = [10, 6] # make the graphs a bit bigger\n",
    "\n",
    "import warnings            # how should we deal with Python warnings?\n",
    "warnings.filterwarnings('ignore') # just ignore them. This is a good rule for life. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative research methods, data science and statistics all rest on the mathematical foundation of probability. We'll make a start in Python by generating some random numbers - imagine rolling two, six sided dice 100 times, and recording the sum of the two dice each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our own Python functions, e.g., one to work out the relative frequency of a score. You can think of this as the experimental probability of rolling a particular score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we find the relative frequency of each possible score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about seeing these on a bar chart?\n",
    "```python\n",
    "plt.bar(x, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three key measures of what's typical - the average. They are the mean, median and mode. Let's write some code to work out the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median and mode are a bit harder, but let me walk you through the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqtable(data):\n",
    "    freqtable = {}\n",
    "    for i in data:\n",
    "        if i in freqtable.keys():\n",
    "            freqtable[i] += 1\n",
    "        else:\n",
    "            freqtable[i] = 1\n",
    "    return(freqtable)\n",
    "\n",
    "freqtable(example)\n",
    "\n",
    "sorted(freqtable(example).items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(freqtable(example).keys(),freqtable(example).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymode(data):\n",
    "    mode = 0\n",
    "    max = 0\n",
    "    freqs = freqtable(data)\n",
    "    for i in freqs.keys():\n",
    "        if freqs[i]>max:\n",
    "            max=freqs[i]\n",
    "            mode = i\n",
    "    return mode\n",
    "\n",
    "mymode(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work out the median, we need the data in order. Let's write some code to sort it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymedian(data):\n",
    "    l = len(data)\n",
    "    if l % 2 == 1:\n",
    "        return quicksort(data)[l // 2]\n",
    "    else:\n",
    "        return quicksort(data)[(l+1)//2]\n",
    "    \n",
    "mymedian(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key measure of spread is the standard deviation. There are two methods to calculate this, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysd1(data):\n",
    "    '''sqrt of mean squared deviations'''\n",
    "    m = mymean(data)\n",
    "    squaredDeviations = map(lambda x: (x-m)**2, data)\n",
    "    return sqrt(mymean(squaredDeviations))\n",
    "\n",
    "def mysd2(data):\n",
    "    '''sqrt of (mean of squares - square of means)'''\n",
    "    return sqrt((mymean(map(lambda x: x**2, data)) - mymean(data)**2))\n",
    "\n",
    "print('method 1',mysd1(example))\n",
    "print('method 2',mysd2(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Fortunately, you'll never need to do any of the above. Because so many people use Python for data analysis, there are a number of libraries which make it easy to do all of this and more. The most popular of these is Pandas, which provides a data structure called a DataFrame, which is a bit like a spreadsheet, and a whole load of functions for manipulating these. We'll be using Pandas a lot in this course, so it's worth getting to know it a bit.\n",
    "\n",
    "Let's start again by loading some standard libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert our dice rolls to a Pandas data frame and revisit the statistics we've calculated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot a histogram of the frequency of each score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with a real dataset\n",
    "\n",
    "We can use the `read_excel` function to read in an Excel spreadsheet. We'll use pre test and post test scores from a class of 31 pupils. There are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate some descriptive statistics for these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's draw some charts to visualise these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot is easier to read if we show the diagonal line where the pre and post test scores are the same.\n",
    "\n",
    "```python\n",
    "g.axline(xy1=(0, 0), xy2=(100,100), color=\"b\", dashes=(2,2))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So did pupils perform better after the intervention? How would you decide? What other information would you need? Might the difference in scores be due to chance?\n",
    "\n",
    "If we have normally distributed data, we can use a t-test to compare the means of two samples. First, we should check that the data appears to be normal. `stats.normaltest` checks this - if the p value is less that 0.05 we should be very careful.\n",
    "\n",
    "For the t-test itself, We can use the `ttest_rel` function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to search for the following. It's not obvious!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pretest', 'posttest']\n",
    "\n",
    "# create the figure and axes\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes = axes.ravel()  # flattening the array makes indexing easier\n",
    "\n",
    "for col, ax in zip(cols, axes):\n",
    "    sns.histplot(data=scores[col], kde=True, stat='density', ax=ax, binrange=(0,100),binwidth=10)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
