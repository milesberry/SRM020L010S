---
title: Quantitative Research Approaches – SMR020L010S
subtitle: University of Roehampton MA Social Research Methods
author: Prof Miles Berry
date: 2024-1-30
bibliography: SRM.bib
format: 
  gfm: default
  pdf:
    template: default.latex
csl: harvard.csl
colorlinks: True
nocite: |
    @balnaves2001, @bryman2012, @burnett2021, @cairo2013, @coe2013, @cohen2018, @denscombe2014, @gignac2019, @goldacre2013, @hart2011, @holcomb2017, @hovy2022, @hoy2010, @ioannidis2014, @jung2002, @kemp2019, @kirk2019, @magallanesreyes2017, @mann2016, @mckinney2022, @mclevey2021, @muijs2011, @nancyl.marshall2009, @oecd2023, @parsons2017, @rajagopalan2021, @spiegelhalter2019, @stojiljkovic, @summers2005, @thrane2023, @urdan2005, @vanderplas2023, @wickham2010, @wilke2019, @stevens1946, @brooker2019
---
\newpage

# Introduction

> Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.  
*Samuel S Wilks*

Quantitative research approaches are typically sited within and empiricist paradigm, which seeks to understand the social world through measurement, analysis and experiment. It borrows heavily from the scientific method, whilst acknowledging that measurement and observation of social phenomena rarely enjoys the precision or objectivity of the natural sciences. 

Quantitative research is often contrasted with qualitative research, which is more concerned with understanding the meaning of social phenomena from the perspective of those involved, and which is more likely to be sited within an interpretivist paradigm. In practice, the distinction between quantitative and qualitative research is not always clear cut, and many research projects will draw on both approaches.

> Quantitative researchers are concerned with the development and testing of hypotheses and the generation of models and theories that explain behaviour. [@hoy2010]

During the coalition and Conservative governments from 2010, educational policy in England has been increasingly led by quantitative approaches. @goldacre2013 makes a strong case for using the sort of randomised control trials seen in medicine to evaluate educational interventions, and this has been taken up by the Education Endowment Foundation[^1], which has funded a number of such trials. 

[^1]: <https://educationendowmentfoundation.org.uk/>

Quantitative research methods are fundamentally concerned with data - information in a well-structured, often tabular, form, typically expressed as numbers. Quantitative methods thus deal with things that can be counted or measured, or with other forms of data that might be converted into numbers. Quantitative methods today make much use of computation, allowing large data sets to be analysed and visualised in ways that would have been impossible in the past.

This module is a practical one, with an emphasis on data analysis and manipulation. You learn how to collect and organise numerical data, how to work with it, how to develop narratives from this data and how to use data to answer research questions. You have the opportunity to experiment with advanced digital methods and associated tools and to gain hands-on experience of applying digital methods to questios in education.  

We'll explore a wide range of scenarios relevant to present day concerns, seeing how data can help us understand complex systems, identify patterns, relationships and exceptions and, sometimes, suggest possible explanations. We explore new tools and approaches in each session, with ample opportunity to put these to use, independently and with my support.  

Our approach begins with obtaining and then cleaning the data, making sure that it's in a *tidy* form that can be readily analysed. Much of the time, we'll draw on techniques of exploratory data analysis, using digital technology to transform data sets to reveal patterns and anomalies, and making the most of the visualisation tools which digital technology provides. Sometimes we'll try to fit models to explain the relationships and the differences within the data we study, and I'll explain the statistical concepts on which this approach draws. More importantly, you'll learn about communicating what you discover in your investigations, writing with impact and authority, using well chosen visualisation to illustrate your point. You'll learn about some key statistical techniques to demonstrate the *significance* of your findings, and the *confidence* with which you can assert them.

We are much more concerned with ideas than tools, but you'll need to develop a degree of fluency with analytical tools. Whilst much can be done using Microsoft Excel, Tableau or SPSS, modern data science makes use of programming for much of its power, so here we introduce you to the Python programming language[^2], and the Pandas toolkit for data analysis[^3]. You'll learn how to use Jupyter notebooks[^4] to combine code, data and narrative, and how to use Python to create visualisations using the Seaborn[^5] and Plotly[^6] libraries. You'll also learn how to use Google Colab[^7] to run Python code in the cloud, without needing to install any software on your own computer. 

[^2]: <https://www.python.org/>
[^3]: <https://pandas.pydata.org/>
[^4]: <https://jupyter.org/>
[^5]: <https://seaborn.pydata.org/>
[^6]: <https://plotly.com/>
[^7]: <https://colab.research.google.com/>

\rightline{\em{Prof Miles Berry, January 2024}}

## Contact details

Lulham 005,  
Froebel College  
University of Roehampton  
London  
SW15 5PJ  

m.berry@roehampton.ac.uk

0208 392 3241

Virtual office hours: [Mondays, 4:00-6:00 and Thursdays, 4:00-6:00](https://outlook.office.com/bookwithme/user/939eb4ced0d04e70a10a0641b0f78308%40roehampton.ac.uk/meetingtype/WEE7ZvD6X0-pleAYCzY7lw2?anonymous).

## Learning Outcomes

If you successfully complete this course you will:

* be familiar with commonly used ways of presenting quantitative data in
educational and social research, and appreciate their usefulness and
limitations;  
* have an understanding of a range of quantitative methods of analysis;  
* have an understanding of when it is appropriate to apply particular
methods of data collection and analysis;  
* know how to conduct a range of statistical analysis using digital tools including
hypothesis testing, comparison of means, correlation, and regression;  
* be critically reflective about the conduct of quantitative research and be
able to evaluate others’ research; and  
* import, clean and analyse a set of data; give a written explanation of the
nature of the data, illustrate the data with appropriate visualisations; identify and explain patterns and relationships in the data; and discuss the significance of what you find.

\newpage

# Assessment Brief

**Hand in:** **2pm on Wednesday 1 May 2024**, via Turnitin on the module Moodle page.

**Feedback published:** 2pm on 22 May 2024.

**Marks** This is a summative assessment and is worth 100% of your module mark.

### Brief

We agree a suitable dataset for the assignment on or by 12 March 2024. I support you in preparing this for analysis. You import the data to a suitable platform[^8] and provide descriptive statistics and some exploratory visualisations. You identify three interesting questions based on the dataset and offer further visualisations and analysis to answer these. You indicate the statistical significance of your findings, where appropriate. You document this process through a narrative and by inclusion of source code or equivalent. You reflect critically on your approach and conclusions, by reference to the literature on research methods and similar studies. Your report should be no more than 3,500 words, including code.

[^8]: Such as Python / Pandas / Jupyter / Colab, as in the module's lectures.


### Guidance 

You will be assessed on your understanding of statistical concepts and practices, your ability to create effective visualisations which communicate the structure, patterns and relationships present in data observing the conventions of statistical communication, your analysis of the data, including modelling and significance testing where appropriate, and your ability to write a critical commentary which reflects, supports and extends the visualisations and analysis.

1. **Understanding of statistics**  
Have you made appropriate use of summative statistics such as means, medians, quartiles, standard deviations? Has data been appropriate grouped or categorised? Does the type of chart or other visualisation correspond to the nature of the data shown? Where appropriate, have you made reference to confidence of sample statistics?

1. **Use of visualisations**  
Does any chart or other visualisation effectively communicate the data itself? Does it show the structure, pattern or relationship in the data? Does it make comparisons easy? Does it conform to the standards of statistical communication, such as labelled axes, a key or legend and acknowledgement of the data source? Is data presented in a way that does not confuse the reader? Is it easy for the reader to interpret the visualisation correctly? Is it well designed (e.g. good use of colour or shape, an absence of clutter)?

1. **Analysis**
Have you given confidence intervals for means and proportions of sample data, where it is appropriate to do so? Have you compared groups within your data, stating the significance of any differences? Have you identified and explained any relationships between variables? Have you modelled any relationships between variables? Have you tested the significance of any relationships? Have you identified and explained any exceptions or outliers in the data?

2. **Commentary and communication**  
Does the commentary reveal something noteworthy, interesting or surprising in the data? Does the commentary give the source of the data? Does it give a clear, precise description of observed phenomenon? Does it offer an explanation? Is it supported by appropriate reference to research methods literature and similar studies? Does it comment critically on limitations or weaknesses? Is it of an appropriate length? Is it written in a clear, precise style appropriate for scholarly work?

## Submission requirements 

1. **Plagiarism under any circumstances is unacceptable. It is a serious academic offence.** Please refer to the Referencing, Plagiarism & RefWorks section on the Learning Skills Hub on Moodle for guidelines on plagiarism and how to make proper citations.

2. Use the citethemright Harvard[^10] system of reference for all cited quotations and sources. 

[^10]: <https://www.citethemrightonline.com/category-list?docid=CTRHarvard> 

3. It is your responsibility to check you have submitted your work correctly. Your assignment submission must be completed before 2pm on Turnitin to ensure that your work is recorded as submitted on time.

4. Make sure you have received a receipt for your submission, confirming it has been uploaded successfully before the deadline. Where technical problems occur with Turnitin across the University, you will be contacted to inform you of any special arrangements that have been put in place to mitigate any impact.

5. Work submitted up to 2pm, 14 calendar days after the deadline will be marked and feedback will be provided in the normal way. However, in the absence of an extension, it will only be registered formally as a pass (50%). Work submitted after 2pm, 14 calendar days after the deadline will not be marked and the formal mark which goes forward to the grade sheet will be zero (0%).

6. If you feel that you are facing issues that might delay your assignment submission past the deadline, or make it difficult for you to complete it to your best ability, then you should request an extension. You can self-certify or provide evidence of mitigating circumstances. Self certified extensions are for one week, those with evidence are for two weeks. Students with Summaries of Adjustment are automatically granted a two week extension and do not need to apply. Details are online via Nest[^9].

[^9]: <https://roehamptonprod.sharepoint.com/sites/portal/nest/examinations/Pages/mitigating-circumstances.aspx>

7. You may use generative AI for explanations, to generate ideas or to get advice on improving your work.  However, be aware that the material generated by these AI tools may be inaccurate, incomplete, or otherwise problematic. If you include material produced by generative AI it should be cited in the same way as you would cite other references. You will not receive credit for this work. Any plagiarism or other form of cheating will be dealt with under the University of Roehampton academic misconduct policy. 

## Assessment Criteria

### Learning relating to relevant module aims and outcomes

**80-100 (outstanding)**: A sophisticated and comprehensive engagement with module aims and attainment of learning outcomes. 

**70-79 (distinction standard)**: A sophisticated and comprehensive engagement with module aims and attainment of learning outcomes.

**60-69 (merit standard)**: A clear and systematic engagement with module aims and substantial attainment of learning outcomes.

**50-59 (pass standard)**: Engagement with the module aims and attainment of learning outcomes.

**40-49 (fail)**: Very limited engagement with the module aims and attainment of learning outcomes.

**0-40 (fail)**: Fails to engage with the module aims, and learning outcomes are not attained.

### Range and understanding of literature, key concepts and theories 

**80-100 (outstanding)**: Authoritative grasp of a very good range of relevant literature, and in-depth understanding of concepts and techniques,  demonstrating an integration of relevant literature and analysis. A comprehensive integration of relevant literature and analysis

**70-79 (distinction standard)**: Authoritative grasp of a very good range of relevant literature, and in-depth understanding of concepts and techniques, demonstrating an integration of relevant literature and analysis.

**60-69 (merit standard)**: Good understanding of relevant literature, key concepts and techniques, and good use is made of a range of tools and techniques.

**50-59 (pass standard)**: Sound understanding of relevant literature, key concepts and techniques, and appropriate use is made of sources, though these may be limited.

**40-49 (fail)**: A basic understanding of relevant literature, key concepts and techniques. 

**0-40 (fail)**: Lacking in conceptual content and / or the accurate and analytical use of appropriate sources and techniques.

### Analysis of data

**80-100 (outstanding)**: A sophisticated analysis of the data provided. For example, the generation of models drawing upon that exploratory analysis.
Achieves an outstanding critical insight into the data and related educational issues.

**70-79 (distinction standard)**: Statistcs are used to analyse the data in a systematic and in-depth way, and the analysis is clear, coherent and critical, providing insight into complex issues.

**60-69 (merit standard)**: Statistics are applied to analyse the data in a systematic way, and the analysis is clear, coherent and consistent.

**50-59 (pass standard)**: Statistics are applied to the data, and the analysis has some clarity, coherence and criticality.

**40-49 (fail)**: Analysis is largely descriptive and lacking in clarity and coherence.

**0-40 (fail)**: Mainly descriptive, rather than analytical, and fails to make links between analysis and broader context.

### Communication, structure and presentation

**80-100 (outstanding)**: Very good organisation, a precise writing style, and presented in standard English. Visualisations reflect a deep and insightful mastery of statistics, showing a thorough command of the underlying principles and techniques.  

**70-79 (distinction standard)**: Very good organisation, a precise writing style, and presented in standard English.Visualisations indicate an excellent understanding of the principles and practice of statistical communication, providing clear insight into the data in line with models of good practice.  

**60-69 (merit standard)**: Good organisation, a clear writing style, referenced well and presented in standard English. Visualisations indicate a good working knowledge of statistical communication, dopting the standard conventions of statistical presentation.

**50-59 (pass standard)**: Appropriate organisation, an appropriate writing style, is presented in standard English. Visualisations indicate the ability to communicate statistics effectively, possibly despite minor errors, omissions or inconsistencies

**40-49 (fail)**: Lacks appropriate organisation and structure, is presented in non-standard English. Aspects of the visualisations suggest a misunderstanding of statistical concepts or practices. Visualisations include errors, omissions or inconsistencies which impede understanding of the data  

**0-40 (fail)**: Unfocused, poorly organised.  English is poor with errors of spelling, grammar and punctuation. Visualisations are absent, inappropriate or misleading.

\newpage

# Teaching and learning

This module has a practical, hands-on approach. You familiarize yourself with quantitative research approaches through face to face sessions which combine aspects of lecture, seminar and practical lab. The teaching and learning strategy will adopt a problem-solving and situated approach to expose you to real-life scenarios and to data sets.

For the current academic year, these face to face sessions are paired with guided, independent study sessions in alternate weeks, where I suggest readings and practical work and offer data sets for you to explore and analyse.

You must engage fully with sessions and set tasks. Attendance in person and active participation in the seminar sessions are necessary for the successful completion of the course.

For a 20 credit module, there's an expectation that you work about 200 hours, so as well as attending lectures and working on your project, there should be lots of time for independent study. Do read widely, using the book list as a starting point, but also the suggestions for wider reading and listening given below.

Develop your software skills independently: focus on analysis and visualisation using Python (including Pandas and Seaborn via Google's Colab Jupyter Notebook server). 

Most importantly, explore and investigate data sets - we'll agree the dataset for the assignment, and we'll walk through a number together during sessions, but the more practice you have in investigating statistical questions the better you'll do!

Face to face sessions are scheduled for **5:00 pm to 7:00 pm in DB 210**, in alternate weeks, as listed below. 

## Week 1 - getting started, descriptive statistics, Jupyter and Pandas

23/1 Face to face

**Recommended readings**: @spiegelhalter2019  

Hillman D (dir) (2012) [Tails You Win: The Science of Chance](https://www.youtube.com/watch?v=sKiz5smpvE8). BBC

Button, T (2022) [MEI Introduction to Data Science](https://www.kaggle.com/code/tombutton/mei-intro-ds-activity-1/notebook). MEI

**Datasets**: modelling random dice rolls; pre and post test scores for a class.

We discuss the scope and structure of the module, and its assessment. We contrast quantitative methods with qualitative methods, and discuss the extent to which exprimental approaches can be considered appropriate for educational research.

I introduce you foundational ideas of statistics, and we look at how measurs of central tendency (mean, median and mode) can be implemented in Python, whilst demonstrating the Juptyer / Colab environment.

We explore Pandas, a Python library for data analysis, and look at how this can be used to import, manipulate and summarise data. We look at how data can be visualised using Seaborn, another Python library.

## Week 2 - Descriptive statistics

30/1 Indepednent study

**Recommended readings:** Chapter 15 of @denscombe2014; chapters 1 and 2 of @gignac2019

**Dataset:** [2018 Nu3 Carbon Footprint Index](https://www.nu3.de/blogs/nutrition/food-carbon-footprint-index-2018)

This week develops your understanding of descriptive statistics such as the mean, median, mode and standard deviation. You'll also practice your Python and Pandas skills.

In addition to the above readings, read through Hart, G, et al (2021) [Crumbs! Understanding Data: a Dstl biscuit book](https://www.gov.uk/government/publications/crumbs-understanding-data-a-dstl-biscuit-book/crumbs-understanding-data-a-dstl-biscuit-book). Dstl, and then work through Matsui, M (2023) [Introduction to statistics in Python](https://rpubs.com/datttrian/introduction-to-statistics-in-python). RPubs.

## Week 3 - Survey data

6/2 Face to face

**Recommended reading:** Chapters 17 and 25 of @cohen2018.

**Dataset:** IT skills survey for initial teacher training students.

We look at how surveys can be used to collect data, and how this data can be analysed. We look at how to construct a survey, and how to analyse the results. We look at how to visualise survey data, and how to compare the results from different groups.

I provide you with survey data from initial teacher training students, and you construct some visualisations. We perform some analysis comparing results between groups. We discuss the extent to which Likert scale data can be analysed in the same way as interval data.

## Week 4 - data visualisation

13/2 Independent study

**Recommended reading:** @wilke2019 and @wickham2010

**Dataset:** [National Student Survey for 2023](https://www.officeforstudents.org.uk/data-and-analysis/national-student-survey-data/)

In addition to the above readings, explore the tools available in Python's Seaborn library for visualising data. Work through the examples in the [Seaborn tutorial introduction](https://seaborn.pydata.org/tutorial/introduction.html).

I provide you with a Notebook for the National Student Survey data. Create some visualisations to explore this data, and write a short report on your findings.

## Week 5 - linear models

20/2 Face to face

**Recommended reading:** @kemp2019

**Dataset:** [School performance data for 2023](https://www.compare-school-performance.service.gov.uk/download-data?currentstep=region&downloadYear=2022-2023&regiontype=all&la=0)

We look at the ideas of correlation and linear regression. We discuss factor analysis through t-tests and ANOVA, extending this to the idea of generalised linear models.

We explore the school performance data for GCSE results in 2023, and look for relationships between variables. We look at how to visualise these relationships, and how to test for significance.

## Week 6 - linear models continued

27/2 Independent study

**Recommended reading:** @stojiljkovic

**Dataset:** [School performance data for 2023](https://www.compare-school-performance.service.gov.uk/download-data?currentstep=region&downloadYear=2022-2023&regiontype=all&la=0)

Read through @stojiljkovic.

I provide you with a Notebook for offer, uptake and attainment for a GCSE subject from 2023, based on the school performance data. You explore the data, make comparisons between groups of schools and look for relationships between variables. You write a short report on your findings including appropriate visualisations.

## Week 7 - randomised control trials

5/3 Face to face

**Recommended reading:** @goldacre2013, @coe2013, @burnett2021

**Dataset:** To be confirmed

We look at the idea of randomised control trials, and how these can be used to evaluate educational interventions. We look at how to design a randomised control trial, and how to analyse the results.

I hope to provide some raw data from a randomised control trial, and you'll analyse this data, looking for relationships and differences between groups.

## Week 8 - geographical data

12/3 Face to face

**Recommended reading:** Chou, L (2019) [Top 10 map types in data visualization](https://towardsdatascience.com/top-10-map-types-in-data-visualization-b3a80898ea70). Towards Data Science. And [Interactive Maps](https://autogis-site.readthedocs.io/en/2021/notebooks/L5/02_interactive-map-folium.html) from the University of Helsinki's Automating GIS-processes 2021.

**Dataset:** [School performance data for 2023](https://www.compare-school-performance.service.gov.uk/download-data?currentstep=region&downloadYear=2022-2023&regiontype=all&la=0)

We explore some approaches to visualising geographically located data. I introduce you to how data can be overlayed onto maps using Python's Folium interface for Leaflet maps. We discuss some of the ethical issues associated with linking data to highly specific geographical data.

We create a map of school performance data by school. We then aggregate this data by local authority, and create a choropleth map of this data. We link this to demographic data at local authority level, and look for relationships between these variables.

We agree a dataset for the assignment if we have not already done so. I help you prepare this for analysis and we discuss some of the approaches you might take.

## Week 9 - International comparisons

19/3 Independent study

**Recommended reading:** @oecd2023

**Dataset:** [PISA 2023](https://www.oecd.org/pisa/data/)

I prepare a Notebook for the PISA 2023 data, and you explore this data, looking for relationships and differences between countries. You write a short report on your findings including appropriate visualisations.

## Week 10 - Preparing for the assignment

26/3 Independent study

**Recommended reading:** Chapters 38-44 of @cohen2018

**Dataset:** To be confirmed

This week provides an opportunity for you to start exploring the assignment dataset for yourself, drawing together what you've learnt from the previous weeks. I'll be available to answer any questions you might have and help with your analysis. 


\newpage

# Resources

## Wider reading

There's some great data-driven journalism around these days. [The Guardian](https://www.theguardian.com/data) have pioneered this, and typically share the source data for the stories they cover. The style of their articles and visualisations would serve as an excellent model for your own reports. The Economist's [Graphic Detail](https://www.economist.com/graphic-detail/) section is very good too, as is the [Visual Journalism](https://www.ft.com/visual-and-data-journalism) work done at the FT.

BBC Radio 4 have an excellent weekly program, [More or Less](https://www.bbc.co.uk/programmes/b006qshd), which covers statistics in the news. Available as a podcast, online and through BBC Sounds.  

The Office of National Statistics have [an excellent blog](https://blog.ons.gov.uk/) covering many aspects of their work.  The [Open Data Institute blog](https://theodi.org/knowledge-opinion/blog/) is also worth reading.

For quantitative work directly related to education, the [Education Endowment Foundation](https://educationendowmentfoundation.org.uk/) is a good place to start. They've funded a number of randomised control trials, and have a good blog and podcast. The [Sutton Trust](https://www.suttontrust.com/) is another good source of quantitative research on education, as are the [National Foundation for Education Research (NFER)](https://www.nfer.ac.uk/) and Fisher Family Trust's [Education Datalab](https://ffteducationdatalab.org.uk/). The [UK Data Service](https://ukdataservice.ac.uk/find-data/browse/education/) has a limited collection of anonymised, raw data relevant to education research.

## Software

We'll use [Moodle](http://moodle.roehampton.ac.uk) as a repository for datasets, readings and notes, but much of my course materials are also stored on [GitHub](https://github.com/milesberry/SRM020L010S)

In most sessions I'll offer a Python Jupyter notebook to explore the dataset, and encourage you to experiment with this. We'll be using [Google's Colab](https://colab.research.google.com/) implementation of [Jupyter Notebooks](https://jupyter.org/), the [Pandas toolkit](https://pandas.pydata.org/) for working with dataframes, and a number of visualisation libraries including  [Seaborn](https://seaborn.pydata.org/), [Plotly](https://plotly.com/) and Folium, a Python interface for [Leaflet](https://leafletjs.com/). Statistical tests are done using [SciPy](https://www.scipy.org/), and generalised linear models using [scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).

## Bibliography